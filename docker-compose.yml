services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: las_ranitas
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - dbdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres -d las_ranitas"]
      interval: 5s
      timeout: 3s
      retries: 10

  vision:
    build:
      context: ./services/vision
      dockerfile: Dockerfile
    container_name: ranitas-vision
    ports:
      - "8000:8000"
    volumes:
      - ./services/yolo/models:/app/models
      - vision-cache:/root/.cache
      - vision-ollama:/root/.ollama
      # Mount host timezone so container logs/timestamps match host
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
    environment:
      - YOLO_MODEL_PATH=/app/models/yoloe-26x-seg.pt
      - YOLO_CONF=0.25
      - MASK_THRESHOLD=0.5
      - OLLAMA_MODEL=${OLLAMA_MODEL:-qwen2.5vl:7b}
      - OLLAMA_HOST=http://127.0.0.1:11434
      # Set to 0 to avoid auto-pulling the configured OLLAMA model on every container start
      - OLLAMA_AUTO_PULL=${OLLAMA_AUTO_PULL:-0}
      # Container timezone (set TZ in your environment or .env to match host timezone, default UTC)
      - TZ=${TZ:-UTC}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      # Reduce verbosity
      - OLLAMA_DEBUG=ERROR
      - PYTHONWARNINGS=ignore
      - PYTHONUNBUFFERED=0
      - YOLO_CONFIG_DIR=/tmp/ultralytics
    # Use container ENTRYPOINT (entrypoint.sh) to start Ollama + FastAPI
    runtime: nvidia
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://127.0.0.1:11434/api/tags >/dev/null && curl -sf http://localhost:8000/status | python3 -c 'import sys,json; o=json.load(sys.stdin); sys.exit(0 if o.get(\"yolo\",{}).get(\"status\")==\"ready\" else 1)'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s
    restart: unless-stopped

volumes:
  dbdata:
  vision-cache:
  vision-ollama:
